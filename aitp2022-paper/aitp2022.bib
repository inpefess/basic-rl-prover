@article{Shminke2022,
  doi = {10.21105/joss.03849},
  url = {https://doi.org/10.21105/joss.03849},
  year = {2022},
  publisher = {The Open Journal},
  volume = {7},
  number = {71},
  pages = {3849},
  author = {Boris Shminke},
  title = {gym-saturation: an OpenAI Gym environment for saturation provers},
  journal = {Journal of Open Source Software}
}
@InProceedings{10.1007/978-3-030-51054-1_33,
author="Zombori, Zsolt
and Urban, Josef
and Brown, Chad E.",
editor="Peltier, Nicolas
and Sofronie-Stokkermans, Viorica",
title="Prolog Technology Reinforcement Learning Prover",
booktitle="Automated Reasoning",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="489--507",
abstract="We present a reinforcement learning toolkit for experiments with guiding automated theorem proving in the connection calculus. The core of the toolkit is a compact and easy to extend Prolog-based automated theorem prover called plCoP. plCoP builds on the leanCoP Prolog implementation and adds learning-guided Monte-Carlo Tree Search as done in the rlCoP system. Other components include a Python interface to plCoP and machine learners, and an external proof checker that verifies the validity of plCoP proofs. The toolkit is evaluated on two benchmarks and we demonstrate its extendability by two additions: (1) guidance is extended to reduction steps and (2) the standard leanCoP calculus is extended with rewrite steps and their learned guidance. We argue that the Prolog setting is suitable for combining statistical and symbolic learning methods. The complete toolkit is publicly released.",
isbn="978-3-030-51054-1"
}
@InProceedings{10.1007/978-3-642-03359-9_4,
author="Harrison, John",
editor="Berghofer, Stefan
and Nipkow, Tobias
and Urban, Christian
and Wenzel, Makarius",
title="HOL Light: An Overview",
booktitle="Theorem Proving in Higher Order Logics",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="60--66",
abstract="HOL Light is an interactive proof assistant for classical higher-order logic, intended as a clean and simplified version of Mike Gordon's original HOL system. Theorem provers in this family use a version of ML as both the implementation and interaction language; in HOL Light's case this is Objective CAML (OCaml). Thanks to its adherence to the so-called `LCF approach', the system can be extended with new inference rules without compromising soundness. While retaining this reliability and programmability from earlier HOL systems, HOL Light is distinguished by its clean and simple design and extremely small logical kernel. Despite this, it provides powerful proof tools and has been applied to some non-trivial tasks in the formalization of mathematics and industrial formal verification.",
isbn="978-3-642-03359-9"
}
@inproceedings{DBLP:conf/icml/BansalLRSW19,
  author    = {Kshitij Bansal and
               Sarah M. Loos and
               Markus N. Rabe and
               Christian Szegedy and
               Stewart Wilcox},
  editor    = {Kamalika Chaudhuri and
               Ruslan Salakhutdinov},
  title     = {HOList: An Environment for Machine Learning of Higher Order Logic
               Theorem Proving},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning,
               {ICML} 2019, 9-15 June 2019, Long Beach, California, {USA}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {97},
  pages     = {454--463},
  publisher = {{PMLR}},
  year      = {2019},
  url       = {http://proceedings.mlr.press/v97/bansal19a.html},
  timestamp = {Tue, 11 Jun 2019 15:37:38 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/BansalLRSW19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/icml/YangD19
,
  author    = {Kaiyu Yang and
               Jia Deng},
  editor    = {Kamalika Chaudhuri and
               Ruslan Salakhutdinov},
  title     = {Learning to Prove Theorems via Interacting with Proof Assistants},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning,
               {ICML} 2019, 9-15 June 2019, Long Beach, California, {USA}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {97},
  pages     = {6984--6994},
  publisher = {{PMLR}},
  year      = {2019},
  url       = {http://proceedings.mlr.press/v97/yang19a.html},
  timestamp = {Mon, 01 Feb 2021 18:33:40 +0100},
  biburl    = {https://dblp.org/rec/conf/icml/YangD19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@software{the_coq_development_team_2022_5846982,
  author       = {The Coq Development Team},
  title        = {The Coq Proof Assistant},
  month        = jan,
  year         = 2022,
  publisher    = {Zenodo},
  version      = {8.15},
  doi          = {10.5281/zenodo.5846982},
  url          = {https://doi.org/10.5281/zenodo.5846982}
}
@InProceedings{10.1007/978-3-540-71067-7_6,
author="Slind, Konrad
and Norrish, Michael",
editor="Mohamed, Otmane Ait
and Mu{\~{n}}oz, C{\'e}sar
and Tahar, Sofi{\`e}ne",
title="A Brief Overview of HOL4",
booktitle="Theorem Proving in Higher Order Logics",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="28--32",
abstract="The HOLF proof assistant supports specification and proof in classical higher order logic. It is the latest in a long line of similar systems. In this short overview, we give an outline of the HOLF system and how it may be applied in formal verification.",
isbn="978-3-540-71067-7"
}
@inproceedings{NEURIPS2021_4dea382d,
 author = {Wu, Minchao and Norrish, Michael and Walder, Christian and Dezfouli, Amir},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {9330--9342},
 publisher = {Curran Associates, Inc.},
 title = {TacticZero: Learning to Prove Theorems from Scratch with Deep Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/2021/file/4dea382d82666332fb564f2e711cbc71-Paper.pdf},
 volume = {34},
 year = {2021}
}
@InProceedings{10.1007/978-3-030-79876-5_31,
author="Suda, Martin",
editor="Platzer, Andr{\'e}
and Sutcliffe, Geoff",
title="Improving ENIGMA-style Clause Selection while Learning From History",
booktitle="Automated Deduction -- CADE 28",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="543--561",
abstract="We re-examine the topic of machine-learned clause selection guidance in saturation-based theorem provers. The central idea, recently popularized by the ENIGMA system, is to learn a classifier for recognizing clauses that appeared in previously discovered proofs. In subsequent runs, clauses classified positively are prioritized for selection. We propose several improvements to this approach and experimentally confirm their viability. For the demonstration, we use a recursive neural network to classify clauses based on their derivation history and the presence or absence of automatically supplied theory axioms therein. The automatic theorem prover Vampire guided by the network achieves a 41 {\%} improvement on a relevant subset of SMT-LIB in a real time evaluation.",
isbn="978-3-030-79876-5"

}
@InProceedings{10.1007/978-3-642-39799-8_1,
author="Kov{\'a}cs, Laura
and Voronkov, Andrei",
editor="Sharygina, Natasha
and Veith, Helmut",
title="First-Order Theorem Proving and Vampire",
booktitle="Computer Aided Verification",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--35",
abstract="In this paper we give a short introduction in first-order theorem proving and the use of the theorem prover Vampire. We discuss the superposition calculus and explain the key concepts of saturation and redundancy elimination, present saturation algorithms and preprocessing, and demonstrate how these concepts are implemented in Vampire. Further, we also cover more recent topics and features of Vampire designed for advanced applications, including satisfiability checking, theory reasoning, interpolation, consequence elimination, and program analysis.",
isbn="978-3-642-39799-8"
}
@InProceedings{10.1007/978-3-319-62075-6_20,
author="Jakub{\r{u}}v, Jan
and Urban, Josef",
editor="Geuvers, Herman
and England, Matthew
and Hasan, Osman
and Rabe, Florian
and Teschke, Olaf",
title="ENIGMA: Efficient Learning-Based Inference Guiding Machine",
booktitle="Intelligent Computer Mathematics",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="292--302",
abstract="ENIGMA is a learning-based method for guiding given clause selection in saturation-based theorem provers. Clauses from many previous proof searches are classified as positive and negative based on their participation in the proofs. An efficient classification model is trained on this data, classifying a clause as useful or un-useful for the proof search. This learned classification is used to guide next proof searches prioritizing useful clauses among other generated clauses. The approach is evaluated on the E prover and the CASC 2016 AIM benchmark, showing a large increase of E's performance.",
isbn="978-3-319-62075-6"
}
@InProceedings{10.1007/978-3-030-29436-6_29,
author="Schulz, Stephan
and Cruanes, Simon
and Vukmirovi{\'{c}}, Petar",
editor="Fontaine, Pascal",
title="Faster, Higher, Stronger: E 2.3",
booktitle="Automated Deduction -- CADE 27",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="495--507",
abstract="E 2.3 is a theorem prover for many-sorted first-order logic with equality. We describe the basic logical and software architecture of the system, as well as core features of the implementation. We particularly discuss recently added features and extensions, including the extension to many-sorted logic, optional limited support for higher-order logic, and the integration of SAT techniques via PicoSAT. Minor additions include improved support for TPTP standard features, always-on internal proof objects, and lazy orphan removal. The paper also gives an overview of the performance of the system, and describes ongoing and future work.",
isbn="978-3-030-29436-6"
}
@article{OTTEN2003139,
title = {leanCoP: lean connection-based theorem proving},
journal = {Journal of Symbolic Computation},
volume = {36},
number = {1},
pages = {139-161},
year = {2003},
note = {First Order Theorem Proving},
issn = {0747-7171},
doi = {https://doi.org/10.1016/S0747-7171(03)00037-3},
url = {https://www.sciencedirect.com/science/article/pii/S0747717103000373},
author = {Jens Otten and Wolfgang Bibel},
abstract = {The Prolog programimplements a theorem prover for classical first-order (clausal) logic which is based on the connection calculus. It is sound and complete (provided that an arbitrarily large I is iteratively given), and demonstrates a comparatively strong performance.}
}
@inproceedings{NEURIPS2018_55acf853,
 author = {Kaliszyk, Cezary and Urban, Josef and Michalewski, Henryk and Ol\v{s}\'{a}k, Miroslav},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Reinforcement Learning of Theorem Proving},
 url = {https://proceedings.neurips.cc/paper/2018/file/55acf8539596d25624059980986aaa78-Paper.pdf},
 volume = {31},
 year = {2018}
}
@InProceedings{10.1007/978-3-030-29007-8_3,
author="Rawson, Michael
and Reger, Giles",
editor="Herzig, Andreas
and Popescu, Andrei",
title="A Neurally-Guided, Parallel Theorem Prover",
booktitle="Frontiers of Combining Systems",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="40--56",
abstract="We present a prototype of a neurally-guided automatic theorem prover for first-order logic with equality. The prototype uses a neural network trained on previous proof search attempts to evaluate subgoals based directly on their structure, and hence bias proof search toward success. An existing first-order theorem prover is employed to dispatch easy subgoals and prune branches which cannot be solved. Exploration of the search space is asynchronous with respect to both the evaluation network and the existing prover, allowing for efficient batched neural network execution and for natural parallelism within the prover. Evaluation on the MPTP dataset shows that the prover can improve with learning.",
isbn="978-3-030-29007-8"
}
@article{Crouse_Abdelaziz_Makni_Whitehead_Cornelio_Kapanipathi_Srinivas_Thost_Witbrock_Fokoue_2021, title={A Deep Reinforcement Learning Approach to First-Order Logic Theorem Proving}, volume={35}, url={https://ojs.aaai.org/index.php/AAAI/article/view/16780}, abstractNote={Automated theorem provers have traditionally relied on manually tuned heuristics to guide how they perform proof search. Deep reinforcement learning has been proposed as a way to obviate the need for such heuristics, however, its deployment in automated theorem proving remains a challenge. In this paper we introduce TRAIL, a system that applies deep reinforcement learning to saturation-based theorem proving. TRAIL leverages (a) a novel neural representation of the state of a theorem prover and (b) a novel characterization of the inference selection process in terms of an attention-based action policy. We show through systematic analysis that these mechanisms allow TRAIL to significantly outperform previous reinforcement-learning-based theorem provers on two benchmark datasets for first-order logic automated theorem proving (proving around 15% more theorems).}, number={7}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Crouse, Maxwell and Abdelaziz, Ibrahim and Makni, Bassem and Whitehead, Spencer and Cornelio, Cristina and Kapanipathi, Pavan and Srinivas, Kavitha and Thost, Veronika and Witbrock, Michael and Fokoue, Achille}, year={2021}, month={May}, pages={6279-6287} }
@article{DBLP:journals/corr/BrockmanCPSSTZ16,
  author    = {Greg Brockman and
               Vicki Cheung and
               Ludwig Pettersson and
               Jonas Schneider and
               John Schulman and
               Jie Tang and
               Wojciech Zaremba},
  title     = {OpenAI Gym},
  journal   = {CoRR},
  volume    = {abs/1606.01540},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.01540},
  eprinttype = {arXiv},
  eprint    = {1606.01540},
  timestamp = {Fri, 08 Nov 2019 12:51:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/BrockmanCPSSTZ16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/jar/Sutcliffe17,
  author    = {Geoff Sutcliffe},
  title     = {The {TPTP} Problem Library and Associated Infrastructure - From {CNF}
               to TH0, {TPTP} v6.4.0},
  journal   = {J. Autom. Reason.},
  volume    = {59},
  number    = {4},
  pages     = {483--502},
  year      = {2017},
  url       = {https://doi.org/10.1007/s10817-017-9407-7},
  doi       = {10.1007/s10817-017-9407-7},
  timestamp = {Wed, 02 Sep 2020 13:30:01 +0200},
  biburl    = {https://dblp.org/rec/journals/jar/Sutcliffe17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/corr/abs-2202-01344,
  author    = {Stanislas Polu and
               Jesse Michael Han and
               Kunhao Zheng and
               Mantas Baksys and
               Igor Babuschkin and
               Ilya Sutskever},
  title     = {Formal Mathematics Statement Curriculum Learning},
  journal   = {CoRR},
  volume    = {abs/2202.01344},
  year      = {2022},
  url       = {https://arxiv.org/abs/2202.01344},
  eprinttype = {arXiv},
  eprint    = {2202.01344},
  timestamp = {Wed, 09 Feb 2022 15:43:35 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2202-01344.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/corr/abs-1712-09381,
  author    = {Eric Liang and
               Richard Liaw and
               Robert Nishihara and
               Philipp Moritz and
               Roy Fox and
               Joseph Gonzalez and
               Ken Goldberg and
               Ion Stoica},
  title     = {Ray RLLib: {A} Composable and Scalable Reinforcement Learning Library},
  journal   = {CoRR},
  volume    = {abs/1712.09381},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.09381},
  eprinttype = {arXiv},
  eprint    = {1712.09381},
  timestamp = {Thu, 30 Apr 2020 14:45:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1712-09381.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/aicom/Sutcliffe21,
  author    = {Geoff Sutcliffe},
  title     = {The 10th {IJCAR} automated theorem proving system competition - {CASC-J10}},
  journal   = {{AI} Commun.},
  volume    = {34},
  number    = {2},
  pages     = {163--177},
  year      = {2021},
  url       = {https://doi.org/10.3233/AIC-201566},
  doi       = {10.3233/AIC-201566},
  timestamp = {Wed, 15 Sep 2021 16:45:16 +0200},
  biburl    = {https://dblp.org/rec/journals/aicom/Sutcliffe21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Henderson_Islam_Bachman_Pineau_Precup_Meger_2018, title={Deep Reinforcement Learning That Matters}, volume={32}, url={https://ojs.aaai.org/index.php/AAAI/article/view/11694}, abstractNote={ &lt;p&gt; In recent years, significant progress has been made in solving challenging problems across various domains using deep reinforcement learning (RL). Reproducing existing work and accurately judging the improvements offered by novel methods is vital to sustaining this progress. Unfortunately, reproducing results for state-of-the-art deep RL methods is seldom straightforward. In particular, non-determinism in standard benchmark environments, combined with variance intrinsic to the methods, can make reported results tough to interpret. Without significance metrics and tighter standardization of experimental reporting, it is difficult to determine whether improvements over the prior state-of-the-art are meaningful. In this paper, we investigate challenges posed by reproducibility, proper experimental techniques, and reporting procedures. We illustrate the variability in reported metrics and results when comparing against common baselines and suggest guidelines to make future results in deep RL more reproducible. We aim to spur discussion about how to ensure continued progress in the field by minimizing wasted effort stemming from results that are non-reproducible and easily misinterpreted. &lt;/p&gt; }, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David}, year={2018}, month={Apr.} }
@article{DBLP:journals/corr/abs-1709-02878,
  author    = {Danijar Hafner and
               James Davidson and
               Vincent Vanhoucke},
  title     = {TensorFlow Agents: Efficient Batched Reinforcement Learning in TensorFlow},
  journal   = {CoRR},
  volume    = {abs/1709.02878},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.02878},
  eprinttype = {arXiv},
  eprint    = {1709.02878},
  timestamp = {Mon, 13 Aug 2018 16:47:29 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1709-02878.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/corr/abs-1903-00027,
  author    = {Sergey Kolesnikov and
               Oleksii Hrinchuk},
  title     = {Catalyst.RL: {A} Distributed Framework for Reproducible {RL} Research},
  journal   = {CoRR},
  volume    = {abs/1903.00027},
  year      = {2019},
  url       = {http://arxiv.org/abs/1903.00027},
  eprinttype = {arXiv},
  eprint    = {1903.00027},
  timestamp = {Sat, 30 Mar 2019 19:27:21 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1903-00027.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}
@inproceedings{DBLP:conf/tableaux/RawsonR21,
  author    = {Michael Rawson and
               Giles Reger},
  editor    = {Anupam Das and
               Sara Negri},
  title     = {lazyCoP: Lazy Paramodulation Meets Neurally Guided Search},
  booktitle = {Automated Reasoning with Analytic Tableaux and Related Methods - 30th
               International Conference, {TABLEAUX} 2021, Birmingham, UK, September
               6-9, 2021, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {12842},
  pages     = {187--199},
  publisher = {Springer},
  year      = {2021},
  url       = {https://doi.org/10.1007/978-3-030-86059-2\_11},
  doi       = {10.1007/978-3-030-86059-2\_11},
  timestamp = {Mon, 06 Sep 2021 13:59:54 +0200},
  biburl    = {https://dblp.org/rec/conf/tableaux/RawsonR21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{rainbow, title={Rainbow: Combining Improvements in Deep Reinforcement Learning}, volume={32}, url={https://ojs.aaai.org/index.php/AAAI/article/view/11796}, abstractNote={ &lt;p&gt; The deep reinforcement learning community has made several independent improvements to the DQN algorithm. However, it is unclear which of these extensions are complementary and can be fruitfully combined. This paper examines six extensions to the DQN algorithm and empirically studies their combination. Our experiments show that the combination provides state-of-the-art performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. We also provide results from a detailed ablation study that shows the contribution of each component to overall performance. &lt;/p&gt; }, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Hessel, Matteo and Modayil, Joseph and van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David}, year={2018}, month={Apr.} }
@InProceedings{pmlr-v80-espeholt18a,
  title = 	 {{IMPALA}: Scalable Distributed Deep-{RL} with Importance Weighted Actor-Learner Architectures},
  author =       {Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Vlad and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and Legg, Shane and Kavukcuoglu, Koray},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1407--1416},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/espeholt18a/espeholt18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/espeholt18a.html},
  abstract = 	 {In this work we aim to solve a large collection of tasks using a single reinforcement learning agent with a single set of parameters. A key challenge is to handle the increased amount of data and extended training time. We have developed a new distributed agent IMPALA (Importance Weighted Actor-Learner Architecture) that not only uses resources more efficiently in single-machine training but also scales to thousands of machines without sacrificing data efficiency or resource utilisation. We achieve stable learning at high throughput by combining decoupled acting and learning with a novel off-policy correction method called V-trace. We demonstrate the effectiveness of IMPALA for multi-task reinforcement learning on DMLab-30 (a set of 30 tasks from the DeepMind Lab environment (Beattie et al., 2016)) and Atari57 (all available Atari games in Arcade Learning Environment (Bellemare et al., 2013a)). Our results show that IMPALA is able to achieve better performance than previous agents with less data, and crucially exhibits positive transfer between tasks as a result of its multi-task approach.}
}
@inproceedings{
horgan2018distributed,
title={Distributed Prioritized Experience Replay},
author={Dan Horgan and John Quan and David Budden and Gabriel Barth-Maron and Matteo Hessel and Hado van Hasselt and David Silver},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=H1Dy---0Z},
}
@InProceedings{FLoP,
author="Zombori, Zsolt
and Csisz{\'a}rik, Adri{\'a}n
and Michalewski, Henryk
and Kaliszyk, Cezary
and Urban, Josef",
editor="Das, Anupam
and Negri, Sara",
title="Towards Finding Longer Proofs",
booktitle="Automated Reasoning with Analytic Tableaux and Related Methods",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="167--186",
abstract="We present a reinforcement learning (RL) based guidance system for automated theorem proving geared towards Finding Longer Proofs (FLoP). Unlike most learning based approaches, we focus on generalising from very little training data and achieving near complete confidence. We use several simple, structured datasets with very long proofs to show that FLoP can successfully generalise a single training proof to a large class of related problems. On these benchmarks, FLoP is competitive with strong theorem provers despite using very limited search, due to its ability to solve problems that are prohibitively long for other systems.",
isbn="978-3-030-86059-2"
}
@inproceedings{fCoP,
author = {Kaliszyk, Cezary and Urban, Josef and Vysko\v{c}il, Ji\v{r}i},
title = {Certified Connection Tableaux Proofs for HOL Light and TPTP},
year = {2015},
isbn = {9781450332965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2676724.2693176},
doi = {10.1145/2676724.2693176},
abstract = {In recent years, the Metis prover based on ordered paramodulation and model elimination has replaced the earlier built-in methods for general-purpose proof automation in HOL4 and Isabelle/HOL. In the annual CASC competition, the leanCoP system based on connection tableaux has however performed better than Metis. In this paper we show how the leanCoP's core algorithm can be implemented inside HOL Light. leanCoP's flagship feature, namely its minimalistic core, results in a very simple proof system. This plays a crucial role in extending the MESON proof reconstruction mechanism to connection tableaux proofs, providing an implementation of leanCoP that certifies its proofs. We discuss the differences between our direct implementation using an explicit Prolog stack,to the continuation passing implementation of MESON present in HOL Light and compare their performance on all core HOL Light goals. The resulting prover can be also used as a general purpose TPTP prover. We compare its performance against the resolution based Metis on TPTP and other interesting datasets.},
booktitle = {Proceedings of the 2015 Conference on Certified Programs and Proofs},
pages = {59–66},
numpages = {8},
keywords = {interactive theorem proving, connection tableaux, certified proofs, leancop, automated reasoning, hol light},
location = {Mumbai, India},
series = {CPP '15}
}
@article{Schulman2017ProximalPO,
  title={Proximal Policy Optimization Algorithms},
  author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  journal={ArXiv},
  year={2017},
  volume={abs/1707.06347}
}
@inproceedings{CurriculumLearning,
author = {Bengio, Yoshua and Louradour, J\'{e}r\^{o}me and Collobert, Ronan and Weston, Jason},
title = {Curriculum Learning},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553380},
doi = {10.1145/1553374.1553380},
abstract = {Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them "curriculum learning". In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {41–48},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}
@article{VectorRepresentations,
    author = {PurgaŁ, StanisŁaw and Parsert, Julian and Kaliszyk, Cezary},
    title = "{A study of continuous vector representations for theorem proving}",
    journal = {Journal of Logic and Computation},
    volume = {31},
    number = {8},
    pages = {2057-2083},
    year = {2021},
    month = {02},
    abstract = "{Applying machine learning to mathematical terms and formulas requires a suitable representation of formulas that is adequate for AI methods. In this paper, we develop an encoding that allows for logical properties to be preserved and is additionally reversible. This means that the tree shape of a formula including all symbols can be reconstructed from the dense vector representation. We do that by training two decoders: one that extracts the top symbol of the tree and one that extracts embedding vectors of subtrees. The syntactic and semantic logical properties that we aim to preserve include both structural formula properties, applicability of natural deduction steps and even more complex operations like unifiability. We propose datasets that can be used to train these syntactic and semantic properties. We evaluate the viability of the developed encoding across the proposed datasets as well as for the practical theorem proving problem of premise selection in the Mizar corpus.}",
    issn = {0955-792X},
    doi = {10.1093/logcom/exab006},
    url = {https://doi.org/10.1093/logcom/exab006},
    eprint = {https://academic.oup.com/logcom/article-pdf/31/8/2057/41808853/exab006.pdf},
}
@article{alon2019code2vec,
 author = {Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran},
 title = {Code2Vec: Learning Distributed Representations of Code},
 journal = {Proc. ACM Program. Lang.},
 issue_date = {January 2019},
 volume = {3},
 number = {POPL},
 month = jan,
 year = {2019},
 issn = {2475-1421},
 pages = {40:1--40:29},
 articleno = {40},
 numpages = {29},
 url = {http://doi.acm.org/10.1145/3290353},
 doi = {10.1145/3290353},
 acmid = {3290353},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Big Code, Distributed Representations, Machine Learning},
}
@Article{Paassen2022,
author="Paa{\ss}en, Benjamin
and Koprinska, Irena
and Yacef, Kalina",
title="Recursive tree grammar autoencoders",
journal="Machine Learning",
year="2022",
month="Aug",
day="02",
abstract="Machine learning on trees has been mostly focused on trees as input. Much less research has investigated trees as output, which has many applications, such as molecule optimization for drug discovery, or hint generation for intelligent tutoring systems. In this work, we propose a novel autoencoder approach, called recursive tree grammar autoencoder (RTG-AE), which encodes trees via a bottom-up parser and decodes trees via a tree grammar, both learned via recursive neural networks that minimize the variational autoencoder loss. The resulting encoder and decoder can then be utilized in subsequent tasks, such as optimization and time series prediction. RTG-AEs are the first model to combine three features: recursive processing, grammatical knowledge, and deep learning. Our key message is that this unique combination of all three features outperforms models which combine any two of the three. Experimentally, we show that RTG-AE improves the autoencoding error, training time, and optimization score on synthetic as well as real datasets compared to four baselines. We further prove that RTG-AEs parse and generate trees in linear time and are expressive enough to handle all regular tree grammars.",
issn="1573-0565",
doi="10.1007/s10994-022-06223-7",
url="https://doi.org/10.1007/s10994-022-06223-7"
}
